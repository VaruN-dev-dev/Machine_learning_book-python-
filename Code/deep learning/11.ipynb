{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd27dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04a0943a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x27be9c40dc0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for vanashing/exploding gradient problems\n",
    "\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "# If you want He initialization with a uniform distribution but based on\n",
    "# fan rather than fan , you can use the VarianceScaling initializer like\n",
    "# this:\n",
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94cfe9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ELU',\n",
       " 'LeakyReLU',\n",
       " 'PReLU',\n",
       " 'ReLU',\n",
       " 'Softmax',\n",
       " 'ThresholdedReLU',\n",
       " 'activation_layers',\n",
       " 'backend',\n",
       " 'deserialize',\n",
       " 'deserialize_keras_object',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'gelu',\n",
       " 'get',\n",
       " 'get_globals',\n",
       " 'hard_sigmoid',\n",
       " 'keras_export',\n",
       " 'leaky_relu',\n",
       " 'linear',\n",
       " 'log_softmax',\n",
       " 'prelu',\n",
       " 'relu',\n",
       " 'relu6',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'serialize_keras_object',\n",
       " 'sigmoid',\n",
       " 'silu',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh',\n",
       " 'tf',\n",
       " 'thresholded_relu']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98473c33",
   "metadata": {},
   "source": [
    "## Non saturating activation functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a31dec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7d77723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a26f2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc829bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.2819 - accuracy: 0.6229 - val_loss: 0.8886 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7955 - accuracy: 0.7362 - val_loss: 0.7130 - val_accuracy: 0.7658\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6816 - accuracy: 0.7720 - val_loss: 0.6427 - val_accuracy: 0.7898\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6217 - accuracy: 0.7944 - val_loss: 0.5900 - val_accuracy: 0.8066\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5832 - accuracy: 0.8074 - val_loss: 0.5582 - val_accuracy: 0.8200\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5553 - accuracy: 0.8157 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5338 - accuracy: 0.8224 - val_loss: 0.5157 - val_accuracy: 0.8304\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5173 - accuracy: 0.8272 - val_loss: 0.5079 - val_accuracy: 0.8286\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5040 - accuracy: 0.8289 - val_loss: 0.4895 - val_accuracy: 0.8390\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4924 - accuracy: 0.8321 - val_loss: 0.4817 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "         validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fbfe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets try the same model with PRelu\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4ce1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddee0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do also see when to use which kernel initializer page->438"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63bc2544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.3461 - accuracy: 0.6209 - val_loss: 0.9255 - val_accuracy: 0.7186\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.8197 - accuracy: 0.7356 - val_loss: 0.7305 - val_accuracy: 0.7628\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.6966 - accuracy: 0.7693 - val_loss: 0.6565 - val_accuracy: 0.7880\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.6331 - accuracy: 0.7909 - val_loss: 0.6004 - val_accuracy: 0.8046\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5917 - accuracy: 0.8057 - val_loss: 0.5656 - val_accuracy: 0.8182\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5618 - accuracy: 0.8135 - val_loss: 0.5406 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5390 - accuracy: 0.8206 - val_loss: 0.5197 - val_accuracy: 0.8312\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5213 - accuracy: 0.8257 - val_loss: 0.5113 - val_accuracy: 0.8316\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5070 - accuracy: 0.8289 - val_loss: 0.4916 - val_accuracy: 0.8378\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4945 - accuracy: 0.8315 - val_loss: 0.4826 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "         validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fba7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is also ELU let't try that also\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.ELU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.ELU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af939f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82a6d665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 1.1201 - accuracy: 0.6462 - val_loss: 0.7927 - val_accuracy: 0.7376\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7228 - accuracy: 0.7570 - val_loss: 0.6571 - val_accuracy: 0.7822\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6316 - accuracy: 0.7878 - val_loss: 0.5999 - val_accuracy: 0.8022\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5824 - accuracy: 0.8044 - val_loss: 0.5562 - val_accuracy: 0.8216\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5508 - accuracy: 0.8149 - val_loss: 0.5306 - val_accuracy: 0.8268\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5281 - accuracy: 0.8201 - val_loss: 0.5113 - val_accuracy: 0.8294\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5108 - accuracy: 0.8253 - val_loss: 0.4957 - val_accuracy: 0.8344\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4975 - accuracy: 0.8300 - val_loss: 0.4888 - val_accuracy: 0.8340\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4867 - accuracy: 0.8315 - val_loss: 0.4744 - val_accuracy: 0.8406\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4771 - accuracy: 0.8351 - val_loss: 0.4679 - val_accuracy: 0.8428\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "         validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be09f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIP:\n",
    "# So, which activation function should you use for the hidden layers of your deep\n",
    "# neural networks? Although your mileage will vary, in general SELU > ELU > leaky\n",
    "# ReLU (and its variants) > ReLU > tanh > logistic. If the network’s architecture\n",
    "# prevents it from self-normalizing, then ELU may perform better than SELU (since\n",
    "# SELU is not smooth at z = 0). If you care a lot about runtime latency, then you may\n",
    "# prefer leaky ReLU. If you don’t want to tweak yet another hyperparameter, you may\n",
    "# use the default α values used by Keras (e.g., 0.3 for leaky ReLU). If you have spare\n",
    "# time and computing power, you can use cross-validation to evaluate other activation\n",
    "# functions, such as RReLU if your network is overfitting or PReLU if you have a\n",
    "# huge training set. That said, because ReLU is the most used activation function (by\n",
    "# far), many libraries and hardware accelerators provide ReLU-specific optimizations;\n",
    "# therefore, if speed is your priority, ReLU might still be the best choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a002be",
   "metadata": {},
   "source": [
    "## Let's create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac4702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e15c97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "413f438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now scaling the inputs\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "679e5283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 31s 17ms/step - loss: 1.1916 - accuracy: 0.5375 - val_loss: 0.7870 - val_accuracy: 0.6970\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 26s 15ms/step - loss: 0.8838 - accuracy: 0.6713 - val_loss: 0.7509 - val_accuracy: 0.7338\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 26s 15ms/step - loss: 0.7145 - accuracy: 0.7366 - val_loss: 0.6534 - val_accuracy: 0.7480\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 26s 15ms/step - loss: 0.6419 - accuracy: 0.7610 - val_loss: 0.6678 - val_accuracy: 0.7536\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 23s 13ms/step - loss: 0.6102 - accuracy: 0.7711 - val_loss: 0.6215 - val_accuracy: 0.7666\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9401d582",
   "metadata": {},
   "source": [
    "now let's do the same with relu instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d7d0fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cde0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "356a9e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 22s 11ms/step - loss: 1.9734 - accuracy: 0.2236 - val_loss: 1.5514 - val_accuracy: 0.3688\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 1.2300 - accuracy: 0.4920 - val_loss: 0.9951 - val_accuracy: 0.6204\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 20s 12ms/step - loss: 1.2264 - accuracy: 0.5311 - val_loss: 0.9492 - val_accuracy: 0.6258\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 22s 13ms/step - loss: 0.9158 - accuracy: 0.6635 - val_loss: 0.9752 - val_accuracy: 0.6756\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 21s 12ms/step - loss: 0.9427 - accuracy: 0.6647 - val_loss: 0.7344 - val_accuracy: 0.7448\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59a28b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the accuracy difference between the two\n",
    "# as you know in relu the function is 0 for -ve values but in ELU the function is -ve so it is\n",
    "# better for dealing with the vanashing/exploding gradients problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05c137",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db2007c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although using He initialization along with ELU (or any variant of ReLU)\n",
    "# can significantly reduce the danger of the vanishing/exploding gradients\n",
    "# problems at the beginning of training, it doesn’t guarantee that they won’t\n",
    "# come back during training.\n",
    "# In a 2015 paper, Sergey Ioffe and Christian Szegedy proposed a technique\n",
    "# called Batch Normalization (BN) that addresses these problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5353f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaa69259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 784)              3136      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_317 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_318 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# As you can see, each BN layer adds four parameters per input: γ, β, μ, and\n",
    "# σ (for example, the first BN layer adds 3,136 parameters, which is 4 ×\n",
    "# 784). The last two parameters, μ and σ, are the moving averages; they are\n",
    "# not affected by backpropagation, so Keras calls them “non-trainable”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f973a559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "754f4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7b75023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8750 - accuracy: 0.7123 - val_loss: 0.5525 - val_accuracy: 0.8232\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5753 - accuracy: 0.8030 - val_loss: 0.4724 - val_accuracy: 0.8478\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5189 - accuracy: 0.8205 - val_loss: 0.4376 - val_accuracy: 0.8546\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4827 - accuracy: 0.8323 - val_loss: 0.4154 - val_accuracy: 0.8602\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4565 - accuracy: 0.8405 - val_loss: 0.3998 - val_accuracy: 0.8634\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4398 - accuracy: 0.8474 - val_loss: 0.3868 - val_accuracy: 0.8692\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4242 - accuracy: 0.8515 - val_loss: 0.3763 - val_accuracy: 0.8710\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4144 - accuracy: 0.8538 - val_loss: 0.3711 - val_accuracy: 0.8742\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.4024 - accuracy: 0.8581 - val_loss: 0.3631 - val_accuracy: 0.8754\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3914 - accuracy: 0.8622 - val_loss: 0.3573 - val_accuracy: 0.8754\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655624f1",
   "metadata": {},
   "source": [
    "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer has some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c20d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edc955a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f18e4a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 1.0317 - accuracy: 0.6756 - val_loss: 0.6767 - val_accuracy: 0.7810\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6790 - accuracy: 0.7793 - val_loss: 0.5566 - val_accuracy: 0.8180\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5960 - accuracy: 0.8037 - val_loss: 0.5007 - val_accuracy: 0.8362\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5447 - accuracy: 0.8191 - val_loss: 0.4666 - val_accuracy: 0.8452\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5109 - accuracy: 0.8280 - val_loss: 0.4434 - val_accuracy: 0.8532\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4898 - accuracy: 0.8339 - val_loss: 0.4263 - val_accuracy: 0.8548\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4712 - accuracy: 0.8395 - val_loss: 0.4130 - val_accuracy: 0.8568\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.4560 - accuracy: 0.8440 - val_loss: 0.4035 - val_accuracy: 0.8606\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4441 - accuracy: 0.8474 - val_loss: 0.3943 - val_accuracy: 0.8642\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.4333 - accuracy: 0.8505 - val_loss: 0.3875 - val_accuracy: 0.8664\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82efef0e",
   "metadata": {},
   "source": [
    "## Gradient Clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18709acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient clippping is oftern used in RNn\n",
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "# page->452 explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e374db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to ensure that Gradient\n",
    "# Clipping does not change the direction of the gradient vector,\n",
    "# you should clip by norm by setting clipnorm instead of clipvalue.\n",
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf8e61a",
   "metadata": {},
   "source": [
    "## Reusing Pre-Trained Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8242bd37",
   "metadata": {},
   "source": [
    "## Reusing a Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ea491",
   "metadata": {},
   "source": [
    "Let's split the fashion MNIST training set in two:\n",
    "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification).\n",
    "We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, \n",
    "t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, \n",
    "only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, \n",
    "since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1634d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b649c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b58b3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f58ab8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.5926 - accuracy: 0.8103 - val_loss: 0.3892 - val_accuracy: 0.8675\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.3523 - accuracy: 0.8788 - val_loss: 0.3290 - val_accuracy: 0.8819\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.3170 - accuracy: 0.8896 - val_loss: 0.3011 - val_accuracy: 0.8989\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2973 - accuracy: 0.8974 - val_loss: 0.2895 - val_accuracy: 0.9016\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2834 - accuracy: 0.9021 - val_loss: 0.2774 - val_accuracy: 0.9066\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2729 - accuracy: 0.9060 - val_loss: 0.2732 - val_accuracy: 0.9066\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2641 - accuracy: 0.9090 - val_loss: 0.2722 - val_accuracy: 0.9083\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2572 - accuracy: 0.9124 - val_loss: 0.2587 - val_accuracy: 0.9143\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2518 - accuracy: 0.9137 - val_loss: 0.2563 - val_accuracy: 0.9145\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2469 - accuracy: 0.9153 - val_loss: 0.2540 - val_accuracy: 0.9155\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2422 - accuracy: 0.9175 - val_loss: 0.2494 - val_accuracy: 0.9155\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2382 - accuracy: 0.9188 - val_loss: 0.2512 - val_accuracy: 0.9131\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2350 - accuracy: 0.9197 - val_loss: 0.2443 - val_accuracy: 0.9158\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 5s 3ms/step - loss: 0.2315 - accuracy: 0.9213 - val_loss: 0.2413 - val_accuracy: 0.9173\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2287 - accuracy: 0.9212 - val_loss: 0.2446 - val_accuracy: 0.9185\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2254 - accuracy: 0.9223 - val_loss: 0.2385 - val_accuracy: 0.9190\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2230 - accuracy: 0.9233 - val_loss: 0.2409 - val_accuracy: 0.9178\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2201 - accuracy: 0.9244 - val_loss: 0.2425 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2178 - accuracy: 0.9251 - val_loss: 0.2328 - val_accuracy: 0.9200\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 4s 3ms/step - loss: 0.2156 - accuracy: 0.9259 - val_loss: 0.2333 - val_accuracy: 0.9208\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e13a3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eecfcf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "169964fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=keras.losses.binary_crossentropy,\n",
    "             optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0df5d8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 37ms/step - loss: 0.9573 - accuracy: 0.4650 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.5692 - accuracy: 0.7450 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.4503 - accuracy: 0.8650 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.3879 - accuracy: 0.8950 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.3435 - accuracy: 0.9250 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.3081 - accuracy: 0.9300 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.2800 - accuracy: 0.9350 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2564 - accuracy: 0.9450 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.2362 - accuracy: 0.9550 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2188 - accuracy: 0.9600 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.2036 - accuracy: 0.9700 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1898 - accuracy: 0.9700 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1773 - accuracy: 0.9750 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1668 - accuracy: 0.9800 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1570 - accuracy: 0.9900 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1481 - accuracy: 0.9900 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.1406 - accuracy: 0.9900 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1334 - accuracy: 0.9900 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1268 - accuracy: 0.9900 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.1208 - accuracy: 0.9900 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc71f184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_10 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_329 (Dense)           (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_330 (Dense)           (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_331 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_332 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_333 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_334 (Dense)           (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10ec3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ec6392",
   "metadata": {},
   "source": [
    "Note that `model_B_on_A` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `model_B_on_A` on top of a *clone* of `model_A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c041cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we do this instead\n",
    "\n",
    "model_A_Clone = keras.models.clone_model(model_A)\n",
    "model_A_Clone.set_weights(model_A.get_weights())\n",
    "model_B_on_A = keras.models.Sequential(model_A_Clone.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44d7b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_B_on_A.compile(loss=keras.losses.binary_crossentropy,\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "955e78a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 42ms/step - loss: 0.2650 - accuracy: 0.9400 - val_loss: 0.2791 - val_accuracy: 0.9280\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.2553 - accuracy: 0.9400 - val_loss: 0.2695 - val_accuracy: 0.9310\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.2459 - accuracy: 0.9400 - val_loss: 0.2608 - val_accuracy: 0.9341\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.2373 - accuracy: 0.9400 - val_loss: 0.2526 - val_accuracy: 0.9361\n",
      "\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 34ms/step - loss: 0.2125 - accuracy: 0.9450 - val_loss: 0.2047 - val_accuracy: 0.9645\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.1701 - accuracy: 0.9550 - val_loss: 0.1722 - val_accuracy: 0.9716\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1410 - accuracy: 0.9650 - val_loss: 0.1495 - val_accuracy: 0.9817\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1199 - accuracy: 0.9800 - val_loss: 0.1328 - val_accuracy: 0.9828\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1048 - accuracy: 0.9900 - val_loss: 0.1203 - val_accuracy: 0.9858\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0931 - accuracy: 0.9950 - val_loss: 0.1104 - val_accuracy: 0.9858\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0839 - accuracy: 0.9950 - val_loss: 0.1023 - val_accuracy: 0.9858\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0764 - accuracy: 0.9950 - val_loss: 0.0955 - val_accuracy: 0.9868\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0700 - accuracy: 0.9950 - val_loss: 0.0894 - val_accuracy: 0.9868\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0643 - accuracy: 0.9950 - val_loss: 0.0846 - val_accuracy: 0.9888\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0598 - accuracy: 0.9950 - val_loss: 0.0802 - val_accuracy: 0.9888\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9888\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.0730 - val_accuracy: 0.9878\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.0702 - val_accuracy: 0.9878\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9878\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 0.0653 - val_accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "print()\n",
    "\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e622bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1408407837152481, 0.9704999923706055]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "412933c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05634359270334244, 0.9940000176429749]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c310e5c7",
   "metadata": {},
   "source": [
    "Great! We got quite a bit of transfer: the error rate dropped by a factor of 4.9!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33f491a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.916666666666718"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100 - 97.05) / (100 - 99.40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7f441a",
   "metadata": {},
   "source": [
    "## Faster optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648fa33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD()\n",
    "\n",
    "# Nesterov Accelerated Gradient\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "# AdaGrad\n",
    "optimizer = keras.optimizers.Adagrad(learning_rate=0.001)\n",
    "\n",
    "# RMSProp\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "\n",
    "# Adam optimization\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Adamax\n",
    "optimizer = keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# Nadam\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375ae56",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f386663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Scheduling\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, decay=1e-4)\n",
    "\n",
    "# page->472\n",
    "# do see other schedules also they are really important"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2c7a27",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca85302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf28ffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 1.5922 - accuracy: 0.8122 - val_loss: 0.7183 - val_accuracy: 0.8328\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.7189 - accuracy: 0.8276 - val_loss: 0.6802 - val_accuracy: 0.8382\n"
     ]
    }
   ],
   "source": [
    "# This is an example\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cac0a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The l2() function returns a regularizer that will be called at each step\n",
    "# during training to compute the regularization loss. This is then added to\n",
    "# the final loss. As you might expect, you can just use\n",
    "# keras.regularizers.l1() if you want ℓ regularization; if you want\n",
    "# both ℓ and ℓ regularization, use keras.regularizers.l1_l2()\n",
    "# (specifying both regularization factors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ceda7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 1.6637 - accuracy: 0.8123 - val_loss: 0.7172 - val_accuracy: 0.8336\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.7168 - accuracy: 0.8285 - val_loss: 0.6838 - val_accuracy: 0.8370\n"
     ]
    }
   ],
   "source": [
    "# Since you will typically want to apply the same regularizer to all layers in\n",
    "# your network, as well as using the same activation function and the same\n",
    "# initialization strategy in all hidden layers, you may find yourself repeating\n",
    "# the same arguments. This makes the code ugly and error-prone. To avoid\n",
    "# this, you can try refactoring your code to use loops. Another option is to\n",
    "# use Python’s functools.partial() function, which lets you create a thin\n",
    "# wrapper for any callable, with some default argument values:\n",
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf47db2",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f540c459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.5716 - accuracy: 0.8030 - val_loss: 0.3666 - val_accuracy: 0.8672\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.4214 - accuracy: 0.8452 - val_loss: 0.3482 - val_accuracy: 0.8714\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab5a64",
   "metadata": {},
   "source": [
    "## Alpha Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25d27cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.6617 - accuracy: 0.7611 - val_loss: 0.5782 - val_accuracy: 0.8406\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5548 - accuracy: 0.7965 - val_loss: 0.5430 - val_accuracy: 0.8488\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5258 - accuracy: 0.8069 - val_loss: 0.5031 - val_accuracy: 0.8562\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.5050 - accuracy: 0.8133 - val_loss: 0.4767 - val_accuracy: 0.8582\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4923 - accuracy: 0.8173 - val_loss: 0.4645 - val_accuracy: 0.8588\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4838 - accuracy: 0.8204 - val_loss: 0.4830 - val_accuracy: 0.8580\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4711 - accuracy: 0.8257 - val_loss: 0.5076 - val_accuracy: 0.8488\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4644 - accuracy: 0.8290 - val_loss: 0.4614 - val_accuracy: 0.8616\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4611 - accuracy: 0.8300 - val_loss: 0.4369 - val_accuracy: 0.8728\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.4527 - accuracy: 0.8307 - val_loss: 0.4410 - val_accuracy: 0.8638\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4479 - accuracy: 0.8339 - val_loss: 0.3947 - val_accuracy: 0.8758\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4439 - accuracy: 0.8331 - val_loss: 0.5277 - val_accuracy: 0.8578\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4421 - accuracy: 0.8351 - val_loss: 0.4177 - val_accuracy: 0.8756\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4382 - accuracy: 0.8369 - val_loss: 0.4337 - val_accuracy: 0.8656\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4320 - accuracy: 0.8393 - val_loss: 0.4545 - val_accuracy: 0.8664\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4298 - accuracy: 0.8405 - val_loss: 0.4303 - val_accuracy: 0.8736\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4290 - accuracy: 0.8421 - val_loss: 0.5082 - val_accuracy: 0.8618\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4273 - accuracy: 0.8398 - val_loss: 0.4643 - val_accuracy: 0.8772\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4240 - accuracy: 0.8421 - val_loss: 0.4715 - val_accuracy: 0.8748\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.4177 - accuracy: 0.8426 - val_loss: 0.4110 - val_accuracy: 0.8748\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3a825c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see MC dropout and Max Norm .. not done here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce48ae6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc074c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ac922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a22c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d9d703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
