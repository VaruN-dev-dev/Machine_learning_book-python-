{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9b175c",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stochastic gradient descent (SGD). \n",
    "\n",
    "## more on..\n",
    "# deals with traning instances, one at a time\n",
    "# it relies on randomness during traning\n",
    "\n",
    "## advantages :\n",
    "# capable of handling very large datasets efficiently\n",
    "\n",
    "\n",
    "## disadvantages :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state = 42)\n",
    "sgd_clf.fit(x_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a31e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance measures\n",
    "# cross-validation\n",
    "\n",
    "# we will use cross_val_score() function to evaluate our\n",
    "# SGDClassifier model using K-fold cross-validation.\n",
    "# K-fold cross.. means splitting the traning set into K-folds.\n",
    "# then making prediction and evaluating them on each K-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, x, y, cv=3, scoring=\"accuracy\")\n",
    "# cv here is the K-fold.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77276116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy is generally not preferred performance measure for \n",
    "# classifier, especially when dealing with skewed datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b4155",
   "metadata": {},
   "source": [
    "# confusion matrix..(under performace measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this we need to have a set of predictions, so they can be \n",
    "# compared to the actual targets.\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "predicted = cross_val_predict(sgd_clf, x, y, cv=3)\n",
    "# here we used cross_val_predict instead of the score one this will\n",
    "# return predictions rather than the score\n",
    "\n",
    "## now confusion matrix..\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, predicted)\n",
    "# here you need to pass the target class and the predicted class\n",
    "# page 93 for explanation of what it returns and what that means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db53b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are other concise metric also like precision, recall\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_train, predicted)\n",
    "\n",
    "recall_score(y_train, predicted)\n",
    "\n",
    "# it is often convenient to combine precision and recall, i.e. F1 score\n",
    "# it is harmonic mean of precision and recall. So, the classifier will only\n",
    "# get a high F1 score if both precision and recall are high\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train, predicted)\n",
    "\n",
    "# precision/recall tradeoff.. \n",
    "# SGD classifier used a value threshold to detect which is 1 or 0\n",
    "# increasing/decreasing the value of threshold can increase/decrease\n",
    "# the precision and recall\n",
    "# Scikit-Learn does not let you set the threshold directly, but it does give you access to\n",
    "# the decision scores that it uses to make predictions.\n",
    "\n",
    "y_score = sgd_clf.decision_function([some_digit]) # it returns the score\n",
    "threshold = 0\n",
    "y_some_digit_prediction = (y_score > threshold)\n",
    "# the sgd uses a threshold equal to 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb882eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so this is very useful we can get any value of precision or recall that we want...\n",
    "\n",
    "# so first we need to get the scores of all instances in the traning set using cross.. (but we need decision scores)\n",
    "\n",
    "y_socres = cross_val_predict(sgd_clf, x_train, y_train_5, cv=3, method=\"decision_function\")\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recall, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "\n",
    "# it will return a numpy array of the corrosponding threshold... do check docs..\n",
    "# remember we only made y_train_5 and y_test_5... i.e. y values for training and testing\n",
    "\n",
    "# To be more precise you can\n",
    "# search for the lowest threshold that gives you at least 90% precision (np.argmax()\n",
    "# will give us the first index of the maximum value, which in this case means the first\n",
    "# True value):\n",
    "\n",
    "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)]\n",
    "\n",
    "# now to make prediction on traning set..for now \n",
    "y_train_pred_90 = (y_scores >= threshold_90_precision)\n",
    "\n",
    "now check precision and recall\n",
    "precision_score(y_train_5, y_train_pred_90)\n",
    "# same for recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # summary/explanaiton\n",
    "# the sgd classifier uses a threshold value to determine the predictions..\n",
    "# now we wanna get a model with a specific precision or recall.. how do we do that?\n",
    "# first we get the scores.. of each instance in the training set using\n",
    "# cross_val_predict(clf, x, y, cv=3, method=\"decision_function\") as we need decision function\n",
    "# insted of predictions...\n",
    "# Now with these scores you can compute precision and recall for all possible thresholds\n",
    "# using the precision_recall_curve() function:\n",
    "# precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
    "    \n",
    "# now we get threshold for which the precision is >=0.90 or 90%\n",
    "# threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)] # ~7816"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29b2c7",
   "metadata": {},
   "source": [
    "# multiclass classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acdfecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are 2-types one is one-versus-all and another is one-versus-one\n",
    "\n",
    "# Scikit-Learn detects when you try to use a binary classification algorithm for a multiclass\n",
    "# classification task, and it automatically runs OvA (except for SVM classifiers for\n",
    "# which it uses OvO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712db727",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.fit(x_train, y_train) # see we used the original datasets.. i mean not the y_train_5 one..\n",
    "# Under the hood,\n",
    "# Scikit-Learn actually trained 10 binary classifiers, got their decision scores for the\n",
    "# image, and selected the class with the highest score.\n",
    "\n",
    "# to check you can use decision_function() it will return 10 scores\n",
    "some_digit_scores = sgd_clf.decision_function([some_digit])\n",
    "some_digit_scores # the highest score is what got predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877a891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but what if i want to be specific.. like one-versus-all or one-versus-one\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state = 42)) # see we passed the sgd into it\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "ovo_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d2ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now of course you want to evaluate these classifiers. As usual, you want to use crossvalidation.\n",
    "# Let’s evaluate the SGDClassifier’s accuracy using the cross_val_score()\n",
    "# function:\n",
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "# you can do much better like simply scaling the imputs..\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "# and now can fit in clf, then see using cross_val_score.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a4d7b1",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let say we found the best model for this.. and now we want to analyze the\n",
    "# types of erros it makes\n",
    "# fist is we can look at confusion matrix.. so we need to make predictions using the\n",
    "# corss_val_predict then call the confusion_matrix function as we did earlier\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "# for image representation\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb406545",
   "metadata": {},
   "source": [
    "# multilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1849a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff between multilabel and multiclass\n",
    "# https://www.analyticsvidhya.com/blog/2021/07/demystifying-the-difference-between-multi-class-and-multi-label-classification-problem-statements-in-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feab5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read again from page->105.. cause you need knowledge of other things also.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
